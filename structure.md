# 目录
1. 架构总览
2. 前端   
   - 2.1 技术选型   
   - 2.2 技术架构   
   - 2.3 前端数据流架构   
   - 2.4 前后端通讯架构   
   - 2.5 react-virtualized   
   - 2.6 文件上传   
3. 后端   
4. 上传服务
5. 后台
6. 运维
7. 测试


## 1 架构总览

![总览](https://vcing.net/static/%E6%80%BB%E8%A7%88.jpg)

## 2 前端

### 2.1 技术选型
总体上沿用1.0的主要技术模块，但对所有开源依赖模块进行了更新，并且未来也会定期和这些模块的最新版本保持同步。   
主要模块:   
1. [create-react-app](https://github.com/facebook/create-react-app)
2. [react](https://github.com/facebook/react)
3. [mobx](https://github.com/mobxjs/mobx)
4. [ant-design](https://github.com/ant-design/ant-design)
5. [d3](https://github.com/d3/d3)
6. [react-virtualized](https://github.com/bvaughn/react-virtualized)

### 2.2 基础架构
以 create-react-app 作为初始化模板，加上前端路由([react-router](https://github.com/ReactTraining/react-router))和前端数据流管理库(mobx)作为基础架构。   
以组件(component)和页面(page)两个维度来组织前端页面代码文件结构，通过使用 css-module, url-loader 等模块来解耦组件与组件，组件与页面之间的依赖关系。   

### 2.3 前端数据流架构
以 mobx 作为前端状态管理和数据流解决方案，通过建立和后台对应的数据模型关系，来分离前端数据和页面之间的耦合关系。并且所有动态数据都保持响应式状态，实时和数据库保持同步，保证了用户和数据库，用户和用户之间的数据一致性。   
   
组件和页面按需注入(inject)所需的存储(Store)，并且做到最小化注入，在层级数量较小的情况下使用props传递数据来减少存储的注入。以此来降低单个页面或组件的复杂度。   

### 2.4 前后端通讯架构
DBStore.js 文件作为后端连接和初始化接口的基础存储(store)，所有的数据发送和接受都会通过DBStore中的事件分发器(EventEmitter)来工作。同时，以单例模式实现的DBStore也负责维护和后端保持通讯的websocket连接通道，包括初始化连接，身份验证，断线重连等基础工作。   
   
DBStore的另外一个功能就是讲将所有后端API接口promise化，使全双工的websocket协议可以实现http的单一定向request/response。降低了websocket协议所带来的复杂的通讯逻辑，同时又保留了websocket的减少通讯数据，增加通讯实时性等优点。   
   
基于以上特性，DBStore对外暴露了两种类型的函数:   
* 模拟http请求返回promise作为响应结果载体的普通API   
* 基于正常websocket实现的，可以实时响应数据变化的监视(watch)型API   
在特殊场景下，也可(但不推荐)使用DBStore暴露出的内部EventEmitter核心来监听连接状态变化或所有通讯数据包   
   
对于其他的数据模型存储，只依赖于DBStore所提供的API获取数据，并且将所有获取到的数据转化成可观察(Observable)数据，在数据发生变化时，组件和页面会自动重新渲染该数据。   
   
![Frontend data flow](https://vcing.net/static/Frontend-data-flow.jpg)
   
在此架构下，真正做到了业务逻辑和后端接口的分离。在测试阶段可以单独生成一个 mock-DBStore 作为纯前端的测试数据源，单独测试前端逻辑。也可在后端做大幅度修改的时候通过只修改DBStore来兼容另外一套后端架构。   
   
### 2.5 react-virtualized
> react-virtualized是一个以高效渲染大型列表和表格数据的响应式组件  
    
在之前的1.0版本中，用户只能操作部分上传或者从数据库导入的数据，原因就是浏览器渲染数据需要消耗大量的资源(CPU&MEMORY)，如果数据过大很容易造成卡顿或者浏览器假死。   
   
所以在目前的2.0版本中，已经引入了react-virtualized模块，该模块通过动态渲染数据，即只渲染用户目前可见区域的数据来大大的减少了对于用户计算机资源的消耗。现在理论用户本地上传的文件，只要文件可以被浏览器导入，那么网页上即可以正常渲染，并且操作的流畅度和数据大小没有用直接关系。   
   
数据操作和渲染作为我们产品中非常重要的一环，对该功能的优化是必不可少并且能够极大改善用户体验的。所以通过该模块我们完全可以达到比Office Excel更好的操作数据的体验。而且如果前后端配合，在后端加入数据区块加载和迭代加载的接口，那么用户可操作的数据大小就几乎是无限制的。   
   
### 2.6 文件上传
在目前的1.2版本中已经重写了上传模块，在更早的版本中，因为对数据库的支持并不完善，所以主要的数据来源便是用户通过浏览器上传。但是首先，浏览器使用的http协议本身就并不是一个适合用来做上传的协议，再加上之前的上传逻辑比较简单，所以在遇到大文件和网络异常状况时很容易崩溃，只能重新上传。   
   
在1.0版本的后期，因为大量bug都是由于上传这一环节直接或者间接的引起，所以不得不重写了所有的上传逻辑。   
新的上传模块采用了(nginx-upload-module)[https://github.com/fdintino/nginx-upload-module]作为上传的后端支持，前端根据该模块所提供的协议重新开发了前端上传库。协议原理大致如下:   
1. 用户选择文件后进行迭代切割   
2. 将切割好的数据块以一定的并发量进行迭代上传   
3. 如果用户手动暂停或遇到网络中断，则记录下当前已完成上传的区块，丢弃未完成上传的区块上传连接。   
4. 恢复上传后，继续传输未上传的数据块   
5. 全部数据块上传完成后，服务器将所有区块拼接成一个完整的文件   
在以上流程中，前端可以控制的参数有两个:
* 单次上传的数据块大小   
* 上传并发数量   
目前默认的配置是4MB的区块大小和4并发上传，目前这个配置在我们的几台国内测试服务器进行上传基本上能够达到最大带宽上传速度，但实际上针对不同的服务器配置，网络环境，这两个参数还可以进行调整，进一步提高上传速度和体验。   
另外，通过上面的流程也不难发现，上传其实是没有时间跨区或者上传来源要求的。虽然我们目前仅支持在浏览器页面不关闭的前提下进行断点续传，但是在后期的优化过程中是可以做到在页面重新打开甚至电脑重启之后继续上传的。并且在特殊场景下也可以实现多地多次分布式上传。   
   
### 2.7 d3   

## 3 后端
## 4 上传服务
### 4.1 总体流程
### 4.2 分布式方案
### 4.3 限制和弊端
### 4.4 替代方案和扩展